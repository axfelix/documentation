---
id: tuning
title: Temporal Server Tuning
sidebar_label: Tuning
description: This section provides a guide to tuning a Temporal Server.
toc_max_heading_level: 4
keywords:
- defaults
- how-to
- limits
- metrics
- production-readiness
- scaling
- self-hosting
- versioning
tags:
- defaults
- how-to
- limits
- metrics
- production-readiness
- scaling
- self-hosting
- versioning
---

<!-- THIS FILE IS GENERATED. DO NOT EDIT THIS FILE DIRECTLY -->

This section provides a guide to tuning a Temporal Server.

## Scaling and Metrics {#scaling-and-metrics}

The requirements of your Temporal system will vary widely based on your intended production workload.
You will want to run your own proof of concept tests and watch for key metrics to understand the system health and scaling needs.

**Load testing.** You can use [the Maru benchmarking tool](https://github.com/temporalio/maru/) ([author's guide here](https://mikhail.io/2021/03/maru-load-testing-tool-for-temporal-workflows/)), see how we ourselves [stress test Temporal](https://temporal.io/blog/temporal-deep-dive-stress-testing/), or write your own.

All metrics emitted by the server are [listed in Temporal's source](https://github.com/temporalio/temporal/blob/main/common/metrics/defs.go).
There are also equivalent metrics that you can configure from the client side.
At a high level, you will want to track these 3 categories of metrics:

- **Service metrics**: For each request made by the service handler we emit `service_requests`, `service_errors`, and `service_latency` metrics with `type`, `operation`, and `namespace` tags.
  This gives you basic visibility into service usage and allows you to look at request rates across services, namespaces and even operations.
- **Persistence metrics**: The Server emits `persistence_requests`, `persistence_errors` and `persistence_latency` metrics for each persistence operation.
  These metrics include the `operation` tag such that you can get the request rates, error rates or latencies per operation.
  These are super useful in identifying issues caused by the database.
- **Workflow Execution stats**: The Server also emits counters for when Workflow Executions are complete.
  These are useful in getting overall stats about Workflow Execution completions.
  Use `workflow_success`, `workflow_failed`, `workflow_timeout`, `workflow_terminate` and `workflow_cancel` counters for each type of Workflow Execution completion.
  These include the `namespace` tag.

## Temporal Platform defaults {#platform-defaults}

:::caution

For the latest information on the Temporal Cloud default limits, see [What are the Temporal Cloud default limits?](/cloud/operating-envelope#default-limits)

:::

This page details many of the defaults coded into the Temporal Platform that can produce errors and warnings.
Errors are hard limits that fail when reached.
Warnings are soft limits that produce a warning log on the server side.

:::note

These limits apply specifically to each Workflow Execution and do not pertain to the entire Temporal Platform or individual Namespaces.

:::

- **Identifiers:** By default, the maximum length for identifiers (such as Workflow Id, Workflow Type, and Task Queue name) is 1000 characters.
  - This is configurable with the `limit.maxIDLength` dynamic config variable, set to 255 in [this SQL example](https://github.com/temporalio/docker-compose/blob/93d382ef9133e4cde8ce311de5153cd0cc9fbd0c/dynamicconfig/development-sql.yaml#L1-L2).
  - The character format is UTF-8.
- **gRPC:** gRPC has a limit of 4 MB for [each message received](https://github.com/grpc/grpc/blob/v1.36.2/include/grpc/impl/codegen/grpc_types.h#L466).
- **Event batch size:** The `DefaultTransactionSizeLimit` limit is [4 MB](https://github.com/temporalio/temporal/pull/1363).
  This is the largest transaction size allowed for the persistence of Event Histories.
- **Blob size limit** for Payloads (including Workflow context and each Workflow and Activity argument and return value; _[source](https://github.com/temporalio/temporal/blob/v1.7.0/service/frontend/service.go#L133-L134)_):
  - Temporal warns at 256 KB: [Blob size exceeds limit.](https://github.com/temporalio/temporal/blob/fee1c43823699e90b330680a8efeb9d8dbee8cf3/common/util.go#L568)
  - Temporal errors at 2 MB: `ErrBlobSizeExceedsLimit: Blob data size exceeds limit.`
  - This is configurable with [BlobSizeLimitError and BlobSizeLimitWarn](https://github.com/temporalio/temporal/blob/v1.7.0/service/history/configs/config.go#L378-L379), if you know what you are doing.
- **History total size limit** (leading to a terminated Workflow Execution):
  - Temporal warns at 10 MB: `history size exceeds warn limit`.
  - Temporal errors at 50 MB: [history size exceeds error limit](https://github.com/temporalio/temporal/blob/v1.7.0/service/history/workflowExecutionContext.go#L1204).
  - This is configurable with [HistorySizeLimitError and HistorySizeLimitWarn](https://github.com/temporalio/temporal/blob/v1.7.0/service/history/configs/config.go#L380-L381), if you know what you are doing.
- **History total count limit** (leading to a terminated Workflow Execution):
  - Temporal warns after 10,240 Events: `history size exceeds warn limit`.
  - Temporal errors after 51,200 Events: [history size exceeds error limit](https://github.com/temporalio/temporal/blob/v1.7.0/service/history/workflowExecutionContext.go#L1204).
  - This is configurable with [HistoryCountLimitError and HistoryCountLimitWarn](https://github.com/temporalio/temporal/blob/v1.7.0/service/history/configs/config.go#L382-L383), if you know what you are doing.
- **Concurrent limit**
  - We fail the following action Commands on Temporal Cloud if the concurrent pending count exceeds 2,000:
    - `ScheduleActivityTask`
    - `SignalExternalWorkflowExecution`
    - `RequestCancelExternalWorkflowExecution`
    - `StartChildWorkflowExecution`
  - As of v1.21, the open source Temporal Cluster has a default limit of 2,000 pending Activities, Child Workflows, Signals, or Workflow cancellation requests, but you can override the limits in the dynamic configuration using these variables:
    - `limit.numPendingActivities.error`
    - `limit.numPendingSignals.error`
    - `limit.numPendingCancelRequests.error`
    - `limit.numPendingChildExecutions.error`
  - By default, [Batch jobs](/cli/batch) are limited to one job at a time.
- [Custom Search Attributes limits](/visibility/#custom-search-attributes-limits)

For details on dynamic configuration keys, see [Dynamic configuration reference](/references/dynamic-configuration#).

## Workflow Versioning {#workflow-versioning}

### Future-proofing your Payloads

One of the easiest things you can do to future-proof your Workflows is to ensure that the inputs and outputs of your Workflows and [Activities](/activities) are ready for changes.
The first step is to use one object, struct, or similar for each input and output.

For example, rather than defining your Workflow like this—

```typescript
export async function myWorkflow(foo: string): Promise<string>;
```

—define it like this:

```typescript
type MyWorkflowInput = { foo: string };
type MyWorkflowOuptut = { result: string };
export async function myWorkflow(
  foo: MyWorkflowInput,
): Promise<MyWorkflowOutput>;
```

By using this technique, you can add fields in a way that will be compatible with existing [Event Histories](/workflows#event-history) (assuming you use a [Payload Converter](/dataconversion#payload-converter) that can deserialize older [Payloads](/dataconversion#payload), such as JSON).
We recommend doing this for all your Workflows and Activities in production.

You can go even farther by defining your inputs and outputs using [Protocol Buffers (protobuf)](https://protobuf.dev/) or another interface definition language (IDL).
We support protobuf with built-in converters.

### Dealing with very long-lived or very event-heavy Workflows

If you know that your Workflow will live for a very long time or generates a large volume of [Events](/workflows#event), you need to deal with the Event [limits](/workflows#limits) and [Continue-As-New](/workflows#continue-as-new) at some point.

One technique to prepare for this eventuality (and at the same time make your life easier when you need to make changes to the [Workflow Definition](/workflows#workflow-definition)) is to structure your Workflow as an "entity Workflow."

### Make all non-transient state serializable

You already defined your Workflow input as an object or struct like we mentioned in the previous section, right?
If you didn't, do that.

The struct should be capable of representing all state that your Workflow cares about.
Because it is also your Workflow input, it must be serializable.

In practice, this often ends up looking like a state machine.

### Continue-As-New on demand

Set up a mechanism to force your Workflow to Continue-As-New on demand.
The easiest way to do this is to define a Signal handler that continues the Workflow when received.
Be sure that all previously received Signals have been processed and that all running [Child Workflows](/workflows#child-workflow) have been waited on or otherwise dealt with.

The newly started Workflow then unpacks the state in the input and can "resume" the Workflow according to your business logic.

A huge benefit of this approach is that you avoid making patches to running Workflows.
Instead, tell them all to continue onto a new [Task Queue](/workers#task-queue) with [Workers](/workers) that have the updated Workflow code.

### When and how to make changes to your Workflow code

When you have an understanding of the importance of writing deterministic Workflow code, you might find yourself grappling with the best way to make changes to that code.

Three approaches are available to you at this time: Task Queue–based versioning, Workflow Name–based versioning, and the Patch and GetVersion APIs.
Each approach has merits and demerits.
(We're also [working toward](https://github.com/temporalio/proposals/blob/master/versioning/worker-versions.md) making Task Queue–based versioning a first-class concept built into Temporal, but that's not quite ready.)

The fundamental recommendation here is to use [Task Queue–based versioning](#task-queuebased-versioning) whenever you can, and use the [Patch and GetVersion APIs](#patch-and-getversion-apis) if your Workflows live long enough that you cannot afford to wait for them to complete before changing their behavior.

### Task Queue–based versioning

In this approach, after you make changes to your Workflow code, deploy your Workers pointed at a new Task Queue instead of the existing one.
For example, if you were targeting the Task Queue `tq-v1`, you'd now target `tq-v2` or similar.
You must also update whatever sources are starting new Workflows to point at the new Task Queue name.
Leave your old Workers running, possibly reducing the number of instances, until no more open Workflows are on `tq-v1`.
Then you can decommission all of them.

**Advantages**

- Conceptually simple.
- Robust.
  Changes are isolated from each other in a way that makes mistakes unlikely.

**Disadvantages**

- Operationally complex (need to keep old Workers alive and change the Task Queue that clients point to).
  This approach can result in multiple sets of old Workers, especially with long-running Workflows.
- Can't be used to fix a bug in currently running or open Workflows.

### Patch and GetVersion APIs

By using functions available in our SDKs, you can branch in your Workflow code based on whether the Workflow is running with newer or older code.
The APIs take slightly different forms depending on the language you're using.
For details, see the language-specific links in [Workflow Versioning](/workflows#workflow-versioning).

**Advantages**

- Don't need to change where Workflow starters are pointing.
- Lets you change the yet-to-be-executed behavior of currently open Workflows while remaining compatible with existing Event Histories.
  The behavior of new Workflows always takes the "new" path.

**Disadvantages**

- Conceptually complex.
- Cognitive burden of needing to understand how both the "old" and "new" code paths work.
- If used indefinitely on the same Workflow Definition, can lead to a mess of branching.

